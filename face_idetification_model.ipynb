{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from  PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "face_cascade = cv2.CascadeClassifier('data/haarcascade_frontalface_alt2.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = os.path.join(base_dir,\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_labels = []\n",
    "current_id =0\n",
    "label_ids = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root , dirs , files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\"png\") or file.endswith(\"jpg\") or file.endswith(\"PNG\") or file.endswith(\"jpeg\") or file.endswith(\"JPEG\") or file.endswith(\"JPG\"):\n",
    "            path = os.path.join(root,file)\n",
    "            \n",
    "            #print(path)\n",
    "            \n",
    "            label = os.path.basename(os.path.dirname(path)).replace(\" \",\"-\").lower()\n",
    "            \n",
    "            \n",
    "            if not label in label_ids:\n",
    "                label_ids[label] = current_id\n",
    "                current_id += 1\n",
    "            ids = label_ids[label]\n",
    "            \n",
    "            \n",
    "            gray = Image.open(path).convert(\"L\") #convert into grayscale\n",
    "                                  \n",
    "            image_array = np.array(gray) #take pixel value of image in numpy array\n",
    "            \n",
    "#             resized_gray = cv2.resize(image_array ,(200,200))\n",
    "\n",
    "            faces = face_cascade.detectMultiScale(image_array,scaleFactor=1.5,minNeighbors=5)\n",
    "            \n",
    "            for (x,y,w,h) in faces:\n",
    "                roi = image_array[y:y+h , x:x+w]\n",
    "                roi = cv2.resize(roi,(100,100))     \n",
    "                x_train.append(roi)                    \n",
    "                y_labels.append(ids)\n",
    "                \n",
    "import pickle\n",
    "\n",
    "with open('labels.pickle','wb') as f:\n",
    "    pickle.dump(label_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(x_train)\n",
    "y_labels = np.array(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[3] , cmap ='gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(vector , possible_values):\n",
    "    '''\n",
    "    For use to one-hot encode the 10- possible labels\n",
    "    '''\n",
    "    n = len(vector)\n",
    "    out = np.zeros((n, possible_values))\n",
    "    out[range(n), vector] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataHelper():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.i = 0\n",
    "        self.training_images = None\n",
    "        self.training_labels = None\n",
    "        \n",
    "        self.test_images = None\n",
    "        self.test_labels = None\n",
    "        \n",
    "        \n",
    "    def set_up_images(self):\n",
    "                \n",
    "        self.training_images = X\n",
    "        train_len = len(self.training_images)\n",
    "        #print(train_len)\n",
    "        \n",
    "        self.training_images = self.training_images.reshape(train_len ,1,100,100).transpose(0,2,3,1)/255\n",
    "        #print(self.training_images[2].shape)\n",
    "        #print(self.training_images.max())\n",
    "        \n",
    "        self.training_labels = one_hot_encode(y_labels, len(np.unique(y_labels)))\n",
    "        #print(self.training_labels)\n",
    "        \n",
    "        self.test_images = X\n",
    "        test_len = len(self.test_images)        \n",
    "        self.test_images = self.test_images.reshape(test_len ,1,100,100).transpose(0,2,3,1)/255\n",
    "        \n",
    "        self.test_labels = one_hot_encode(y_labels, len(np.unique(y_labels)))\n",
    "        \n",
    "        \n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        x = self.training_images[self.i:self.i+batch_size].reshape(1,100,100,1)\n",
    "        y = self.training_labels[self.i:self.i+batch_size]\n",
    "        self.i = (self.i + batch_size) % len(self.training_images)\n",
    "        return x, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ImageDataHelper()\n",
    "b.set_up_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,100,100,1], name=\"inputx\")\n",
    "y_true = tf.placeholder(tf.float32,shape=[None,len(np.unique(y_labels))],name=\"inputy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_prob = tf.placeholder(tf.float32 , name=\"hold_prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist , name = \"weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals , name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_1 = convolutional_layer(x,shape=[4,4,1,100])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_2 = convolutional_layer(convo_1_pooling,shape=[4,4,100,200])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)\n",
    "convo_2_pooling.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_2_flat = tf.reshape(convo_2_pooling,[-1,25*25*200])\n",
    "convo_2_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout,len(np.unique(y_labels)))\n",
    "y_pred = tf.identity(y_pred , name=\"y_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        for i in range(5000):\n",
    "\n",
    "            batch = b.next_batch(1)\n",
    "\n",
    "\n",
    "            sess.run(train, feed_dict={x:batch[0], y_true: batch[1], hold_prob: 0.5})\n",
    "\n",
    "            if i%100 == 0:\n",
    "                \n",
    "                print(y_pred)\n",
    "                print('Currently on step {}'.format(i))\n",
    "                print('Accuracy is:')\n",
    "                # Test the Train Model\n",
    "                matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "                acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "                print(sess.run(acc,feed_dict={x:b.test_images,y_true:b.test_labels,hold_prob:1.0}))\n",
    "                print('\\n')\n",
    "\n",
    "\n",
    "        saver.save(sess,'save_model/face_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
